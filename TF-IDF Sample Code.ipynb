{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Weightage Sample Code\n",
    "This is a sample code to give students an idea of how TF-IDF weightage model can be applied to calculate relevance score of documents.\n",
    "\n",
    "The example is taken from **lecture 3.2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P.S Do not get confused with the answers provided for TF-IDF in lecture 3.2, since the example shown had documents from d1-d5 but in actual the collection was large, hence M and k are actually unknown in that solved solution.** <br>\n",
    "**In this example, M = 5 as it is assumed that the collection has 5 docs only.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style = 'color:purple;'>Vector Space Model (TF-IDF Weightage Model)</h3>\n",
    "\n",
    "$$ f(q,d) = sim(q,d) =  \\sum_{i=1}^n x_iy_i $$ \n",
    "q = (x_1,.....,x_n) <br>\n",
    "d = (y_1,.....,y_n) <br>\n",
    "x_i = count of word W_i in query. <br>\n",
    "y_i = TF-IDF of word W_i in doc i.e $$ y_i = C(W_i,doc) * log_2 \\frac {M+1} {k} $$\n",
    "M = number of documents in the collection <br>\n",
    "k = document frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets say we have the following documents\n",
    "documents = {\n",
    "    \"d1\" : \"news about\",\n",
    "    \"d2\" : \"news about organic food campaign\",\n",
    "    \"d3\" : \"news of presidential campaign\",\n",
    "    \"d4\" : \"news of presidential campaign presidential candidate\",\n",
    "    \"d5\" : \"news of organic food campaign campaign campaign campaign\"\n",
    "} # a dictionary with doc# as key and doc content as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': 'news about',\n",
       " 'd2': 'news about organic food campaign',\n",
       " 'd3': 'news of presidential campaign',\n",
       " 'd4': 'news of presidential campaign presidential candidate',\n",
       " 'd5': 'news of organic food campaign campaign campaign campaign'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the dictionary\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a corpus ccontaining the vocabulary of words in the documents\n",
    "corpus = [] # a list that will store words of the vocabulary\n",
    "for doc in documents.values(): #iterate through documents \n",
    "    for word in doc.split(): #go through each word in the current doc\n",
    "        if not word in corpus: \n",
    "            corpus.append(word) #add word in corpus if not already added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news',\n",
       " 'about',\n",
       " 'organic',\n",
       " 'food',\n",
       " 'campaign',\n",
       " 'of',\n",
       " 'presidential',\n",
       " 'candidate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the corpus \n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a dictionary that will store document frequency for each word in the corpus\n",
    "df_corpus = {} #document frequency for every word in corpus\n",
    "for word in corpus:\n",
    "    k = 0 #initial document frequency set to 0\n",
    "    for doc in documents.values(): #iterate through documents\n",
    "        if word in doc.split(): #check if word in doc\n",
    "            k+=1 \n",
    "    df_corpus[word] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news': 5,\n",
       " 'about': 2,\n",
       " 'organic': 2,\n",
       " 'food': 2,\n",
       " 'campaign': 4,\n",
       " 'of': 3,\n",
       " 'presidential': 2,\n",
       " 'candidate': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the document frequency values\n",
    "df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have calculated k (document frequency) for all the words in the corpus, next step is to calculate idf\n",
    "M = len(documents) #number of documents in the collection\n",
    "idf_corpus = {} #inverse_document frequency for every word in corpus\n",
    "for word in corpus:\n",
    "    idf_corpus[word] = np.log2((M+1) / df_corpus[word]) #log_2 ((M+1)/k) i.e inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news': 0.2630344058337938,\n",
       " 'about': 1.584962500721156,\n",
       " 'organic': 1.584962500721156,\n",
       " 'food': 1.584962500721156,\n",
       " 'campaign': 0.5849625007211562,\n",
       " 'of': 1.0,\n",
       " 'presidential': 1.584962500721156,\n",
       " 'candidate': 2.584962500721156}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize idf values\n",
    "idf_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully calculated inverse_document_frequency for all the words in the corpus. Now, using the idf values, we need to calculate tf-idf for each word with respect to a particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating tf_idf\n",
    "tf_idf_docs = {} #will store tf_idf scores for document words\n",
    "for doc_id in documents.keys():\n",
    "    tf_idf_docs[doc_id] = {} #initialize empty dictionary for each doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': {}, 'd2': {}, 'd3': {}, 'd4': {}, 'd5': {}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize tf_idf initial state\n",
    "tf_idf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalizing the tf_idf calculations\n",
    "for word in corpus:\n",
    "    for doc_id,doc in documents.items(): #iterate through key,value pairs where key = doc_id and value = doc content\n",
    "        tf_idf_docs[doc_id][word] = doc.split().count(word) * idf_corpus[word] #C(W_i,doc) * IDF(W_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': {'news': 0.2630344058337938,\n",
       "  'about': 1.584962500721156,\n",
       "  'organic': 0.0,\n",
       "  'food': 0.0,\n",
       "  'campaign': 0.0,\n",
       "  'of': 0.0,\n",
       "  'presidential': 0.0,\n",
       "  'candidate': 0.0},\n",
       " 'd2': {'news': 0.2630344058337938,\n",
       "  'about': 1.584962500721156,\n",
       "  'organic': 1.584962500721156,\n",
       "  'food': 1.584962500721156,\n",
       "  'campaign': 0.5849625007211562,\n",
       "  'of': 0.0,\n",
       "  'presidential': 0.0,\n",
       "  'candidate': 0.0},\n",
       " 'd3': {'news': 0.2630344058337938,\n",
       "  'about': 0.0,\n",
       "  'organic': 0.0,\n",
       "  'food': 0.0,\n",
       "  'campaign': 0.5849625007211562,\n",
       "  'of': 1.0,\n",
       "  'presidential': 1.584962500721156,\n",
       "  'candidate': 0.0},\n",
       " 'd4': {'news': 0.2630344058337938,\n",
       "  'about': 0.0,\n",
       "  'organic': 0.0,\n",
       "  'food': 0.0,\n",
       "  'campaign': 0.5849625007211562,\n",
       "  'of': 1.0,\n",
       "  'presidential': 3.169925001442312,\n",
       "  'candidate': 2.584962500721156},\n",
       " 'd5': {'news': 0.2630344058337938,\n",
       "  'about': 0.0,\n",
       "  'organic': 1.584962500721156,\n",
       "  'food': 1.584962500721156,\n",
       "  'campaign': 2.3398500028846247,\n",
       "  'of': 1.0,\n",
       "  'presidential': 0.0,\n",
       "  'candidate': 0.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize final tf_idf scores for each doc\n",
    "tf_idf_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the documents for relevance scores\n",
    "Since we have calculated the term frequencies for all the documents in our collection, let us calcualte the relevance score of each document for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'news about presidential campaign'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"news about presidential campaign\" #the query\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vocab = [] # will store the unique words that occur in the query\n",
    "for word in query.split():\n",
    "    if word not in query_vocab:\n",
    "        query_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news', 'about', 'presidential', 'campaign']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vocab # the unique words in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_wc = {} # a dictionary to store count of a word in the query (i.e x_i according to lecture slides terminology)\n",
    "for word in query_vocab:\n",
    "    query_wc[word] = query.split().count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news': 1, 'about': 1, 'presidential': 1, 'campaign': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_wc # the count of each word that occurs in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_scores = {} # a dictionary that will store the relevance score for each doc\n",
    "# doc_id will be the key and relevance score the value for this dictionary\n",
    "for doc_id in documents.keys():\n",
    "    score = 0 #initialze the score for the doc to 0 at the start\n",
    "    for word in query_vocab:\n",
    "        score += query_wc[word] * tf_idf_docs[doc_id][word] # count of word in query * term_freq of the word\n",
    "    relevance_scores[doc_id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Relevancy Scores\n",
      " {'d1': 1.84799690655495, 'd2': 2.432959407276106, 'd3': 2.432959407276106, 'd4': 4.017921907997263, 'd5': 2.6028844087184186}\n"
     ]
    }
   ],
   "source": [
    "# lets print the relevance scores for the query\n",
    "print(\"Document Relevancy Scores\\n\",relevance_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What next ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://media.makeameme.org/created/brace-yourself-assignment-5bb85a.jpg\" alt = \"Assignment is ccoming\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
