{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Weightage Sample Code\n",
    "This is a sample code to give students an idea of how Term-Frequency weightage model can be applied to calculate relevance score of documents.\n",
    "\n",
    "The example is taken from **lecture 3.2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style = 'color:purple;'>Vector Space Model (TF-Weightage Model)</h3>\n",
    "\n",
    "$$ f(q,d) = sim(q,d) =  \\sum_{i=1}^n x_iy_i $$ \n",
    "q = (x_1,.....,x_n) <br>\n",
    "d = (y_1,.....,y_n) <br>\n",
    "x_i = count of word W_i in query. <br>\n",
    "y_i = count of word W_i in doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets say we have the following documents\n",
    "documents = {\n",
    "    \"d1\" : \"news about\",\n",
    "    \"d2\" : \"news about organic food campaign\",\n",
    "    \"d3\" : \"news of presidential campaign\",\n",
    "    \"d4\" : \"news of presidential campaign presidential candidate\",\n",
    "    \"d5\" : \"news of organic food campaign campaign campaign campaign\"\n",
    "} # a dictionary with doc# as key and doc content as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': 'news about',\n",
       " 'd2': 'news about organic food campaign',\n",
       " 'd3': 'news of presidential campaign',\n",
       " 'd4': 'news of presidential campaign presidential candidate',\n",
       " 'd5': 'news of organic food campaign campaign campaign campaign'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the dictionary\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a corpus ccontaining the vocabulary of words in the documents\n",
    "corpus = [] # a list that will store words of the vocabulary\n",
    "for doc in documents.values(): #iterate through documents \n",
    "    for word in doc.split(): #go through each word in the current doc\n",
    "        if not word in corpus: \n",
    "            corpus.append(word) #add word in corpus if not already added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news',\n",
       " 'about',\n",
       " 'organic',\n",
       " 'food',\n",
       " 'campaign',\n",
       " 'of',\n",
       " 'presidential',\n",
       " 'candidate']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the corpus \n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a dictionary within a dictionary to store term-frequncy for each doc\n",
    "tf_docs = {} #empty dictionary\n",
    "for doc_id in documents.keys(): #iterate through doc# (d1,d2,...,d5)\n",
    "    tf_docs[doc_id] = {} #create empty dictionary for each doc# key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': {}, 'd2': {}, 'd3': {}, 'd4': {}, 'd5': {}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the state of tf_docs\n",
    "tf_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have created a dictionary against each doc, now we have to use the created dictionaries to store term frequencies for each doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets start on storing term-frequencies for every doc\n",
    "for word in corpus: #iterate through words in the corpus\n",
    "    for doc_id,doc in documents.items(): #iterate through documents dictionary\n",
    "        tf_docs[doc_id][word] = doc.count(word) #store term-frequency for the word in each doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': {'news': 1,\n",
       "  'about': 1,\n",
       "  'organic': 0,\n",
       "  'food': 0,\n",
       "  'campaign': 0,\n",
       "  'of': 0,\n",
       "  'presidential': 0,\n",
       "  'candidate': 0},\n",
       " 'd2': {'news': 1,\n",
       "  'about': 1,\n",
       "  'organic': 1,\n",
       "  'food': 1,\n",
       "  'campaign': 1,\n",
       "  'of': 0,\n",
       "  'presidential': 0,\n",
       "  'candidate': 0},\n",
       " 'd3': {'news': 1,\n",
       "  'about': 0,\n",
       "  'organic': 0,\n",
       "  'food': 0,\n",
       "  'campaign': 1,\n",
       "  'of': 1,\n",
       "  'presidential': 1,\n",
       "  'candidate': 0},\n",
       " 'd4': {'news': 1,\n",
       "  'about': 0,\n",
       "  'organic': 0,\n",
       "  'food': 0,\n",
       "  'campaign': 1,\n",
       "  'of': 1,\n",
       "  'presidential': 2,\n",
       "  'candidate': 1},\n",
       " 'd5': {'news': 1,\n",
       "  'about': 0,\n",
       "  'organic': 1,\n",
       "  'food': 1,\n",
       "  'campaign': 4,\n",
       "  'of': 1,\n",
       "  'presidential': 0,\n",
       "  'candidate': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_docs #visualize calculated term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news': 1,\n",
       " 'about': 0,\n",
       " 'organic': 0,\n",
       " 'food': 0,\n",
       " 'campaign': 1,\n",
       " 'of': 1,\n",
       " 'presidential': 1,\n",
       " 'candidate': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_docs['d3'] #checking term frequencies for d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the documents for relevance scores\n",
    "Since we have calculated the term frequencies for all the documents in our collection, let us calcualte the relevance score of each document for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'news about presidential campaign'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"news about presidential campaign\" #the query\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vocab = [] # will store the unique words that occur in the query\n",
    "for word in query.split():\n",
    "    if word not in query_vocab:\n",
    "        query_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news', 'about', 'presidential', 'campaign']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vocab # the unique words in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_wc = {} # a dictionary to store count of a word in the query (i.e x_i according to lecture slides terminology)\n",
    "for word in query_vocab:\n",
    "    query_wc[word] = query.split().count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news': 1, 'about': 1, 'presidential': 1, 'campaign': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_wc # the count of each word that occurs in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_scores = {} # a dictionary that will store the relevance score for each doc\n",
    "# doc_id will be the key and relevance score the value for this dictionary\n",
    "for doc_id in documents.keys():\n",
    "    score = 0 #initialze the score for the doc to 0 at the start\n",
    "    for word in query_vocab:\n",
    "        score += query_wc[word] * tf_docs[doc_id][word] # count of word in query * term_freq of the word\n",
    "    relevance_scores[doc_id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Relevancy Scores\n",
      " {'d1': 2, 'd2': 3, 'd3': 3, 'd4': 4, 'd5': 5}\n"
     ]
    }
   ],
   "source": [
    "# lets print the relevance scores for the query\n",
    "print(\"Document Relevancy Scores\\n\",relevance_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOORAY !!!\n",
    "We are done with our first simple vector space model to check the relevancy of each document to our query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What next ?\n",
    "This was just one the many ways you can calculate the relevancy score of query for a set of documents. I tried to comment the code as much as possible for your understanding, it is important that you get familiar with Python coding as early as possible as it will be used throughout your degree program. Please try to understand this code, as it will be useful for solving assignment 1 for this course. Regards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
